Task 1 aims to count the number of prime numbers from an array of numbers treated as strings

Given a text file input: x = {"1", "2", "3", ... "10^9"}

1. Convert the .txt into .rdd (or such that Spark can distribute the data to the slave nodes)

2. Distribute the data to slave nodes (I suppose this can be done via Spark's built in functions)

3. Convert the strings to integers

4. Along with map reduce (I think) use prime.py to search for prime numbers

5. Modify prime.py such that it counts the number of prime numbers

6. Sum up the number of prime numbers and send it to the master node?
